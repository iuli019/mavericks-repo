{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a53d8b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ibalica/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08173c",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b6318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        full_text = []\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                text = re.sub(r'-\\n(\\w+)', r'\\1', text)  \n",
    "                full_text.append(text.replace('\\n', ' '))  \n",
    "    return \" \".join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3492f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    # Remove line breaks\n",
    "    corrected_text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Handling word breaks caused by hyphens at line-ends\n",
    "    corrected_text = re.sub(r'\\b-\\b', '', corrected_text)\n",
    "    \n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec295b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_summarize(text, start_keywords, end_keywords, word_limit=100):\n",
    "    sentences = sent_tokenize(text)\n",
    "    extracted_text = []\n",
    "    capture = False\n",
    "    word_count = 0\n",
    "    extending = False  # To indicate whether we're extending to reach a full stop after the word limit\n",
    "\n",
    "    start_patterns = [r'\\b' + re.escape(keyword) + r'\\b' for keyword in start_keywords]\n",
    "    end_patterns = [r'\\b' + re.escape(keyword) + r'\\b' for keyword in end_keywords]\n",
    "\n",
    "    start_regex = re.compile('|'.join(start_patterns), re.IGNORECASE)\n",
    "    end_regex = re.compile('|'.join(end_patterns), re.IGNORECASE)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if start_regex.search(sentence):\n",
    "            capture = True\n",
    "        if capture:\n",
    "            current_words = sentence.split()\n",
    "            if word_count + len(current_words) > word_limit and not extending:\n",
    "                extending = True  # Start looking for a period to end the summary\n",
    "            word_count += len(current_words)\n",
    "            extracted_text.append(sentence)\n",
    "            if extending and sentence.endswith('.'):\n",
    "                break  # Stop at the first full stop after reaching the word limit\n",
    "            if end_regex.search(sentence):\n",
    "                break\n",
    "\n",
    "    return ' '.join(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82cbe5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "def chunk_text(text, max_length=510, overlap=50):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(tokenized_text):\n",
    "        end = i + max_length\n",
    "        start = max(0, end - overlap)\n",
    "        chunks.append(tokenizer.convert_tokens_to_string(tokenized_text[start:end]))\n",
    "        i += max_length\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddaf9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, context):\n",
    "    # Encode the question-context pair to get input IDs and attention masks\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    # Model prediction\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Find the tokens with the highest `start` and `end` scores\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "\n",
    "    # Convert tokens to answer\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60b5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_context(question, context, max_length=512):\n",
    "    # Tokenize the context alone to avoid repeatedly processing the question\n",
    "    context_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    chunk_size = max_length - len(tokenizer.encode(question, add_special_tokens=True)) - 50  # 50 tokens for some leeway\n",
    "    chunks = [context_tokens[i:i + chunk_size] for i in range(0, len(context_tokens), chunk_size)]\n",
    "    answers = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Decode chunk to text\n",
    "        chunk_text = tokenizer.decode(chunk, clean_up_tokenization_spaces=True)\n",
    "        # Get answer for this chunk\n",
    "        ans = answer_question(question, chunk_text)\n",
    "        answers.append(ans)\n",
    "    \n",
    "    # You can improve this by scoring answers based on confidence or selecting the most frequent answer\n",
    "    return answers[0]  # Naive approach: return the first answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73293727",
   "metadata": {},
   "source": [
    "### Defining Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3ec573",
   "metadata": {},
   "outputs": [],
   "source": [
    "composition_keywords = [\n",
    "    'mg', 'containing', 'active ingredient', 'composition', 'contains', \"Ingredients\", \"Active Ingredients\", \n",
    "    \"Inactive Ingredients\", \"Compounds\", \"Concentration\", \"Formulation\", \"Content\", \"Dosage\", \"Excipients\", \n",
    "    \"Chemical Composition\", \"Additives\", \"Preservatives\", \"Nutritional Information\", \"Allergens\", \"API\", \n",
    "    \"Molecular Formula\", \"Batches\", \"Synthesis\", \"Properties\", \"Standards\"\n",
    "]\n",
    "\n",
    "contraindications_keywords = [\n",
    "    'contraindications', 'do not take', 'not take if', 'warnings', 'do not use', 'should not be taken', \n",
    "    \"Contraindications\", \"Warnings\", \"Precautions\", \"Risk Factors\", \"Avoid\", \"Not Recommended\", \"Hypersensitivity\", \n",
    "    \"Allergic Reactions\", \"Adverse Reactions\", \"Safety Alerts\", \"Interactions\", \"Medical Conditions\", \n",
    "    \"Prohibited\", \"Disallowed\", \"Health Risks\", \"Limitations\", \"Do Not Use If\", \"Exclusion Criteria\", \n",
    "    \"Unsuitable For\", \"Health Warnings\"\n",
    "]\n",
    "\n",
    "adverse_reactions_keywords = [\n",
    "    'stop', 'adverse reactions', 'side effects', 'possible side effects', 'unwanted effects', 'reactions', \n",
    "    \"Adverse Reactions\", \"Side Effects\", \"Complications\", \"Risks\", \"Warnings\", \"Symptoms\", \"Undesirable Effects\", \n",
    "    \"Negative Effects\", \"Harmful Effects\", \"Allergic Reactions\", \"Toxicity\", \"Safety Concerns\", \"Intolerance\", \n",
    "    \"Discomfort\", \"Consequences\", \"Aftereffects\", \"Hypersensitivity\", \"Counteractions\", \"Unwanted Effects\"\n",
    "]\n",
    "\n",
    "pregnancy_keywords = [\n",
    "    'pregnant', 'pregnancy', 'breast-feeding and fertility', 'breast-feeding', 'during pregnancy', \"Pregnancy\", \n",
    "    \"Expectant Mother\", \"Gestation\", \"Trimester\", \"Prenatal Care\", \"Maternity\", \"Obstetrics\", \"Ob/Gyn\", \n",
    "    \"Fetal Development\", \"Ultrasound\", \"Birth Plan\", \"Due Date\", \"Conception\", \"Antenatal\", \"Childbirth\", \n",
    "    \"Labor and Delivery\", \"Postpartum\", \"Breastfeeding\", \"Infant Care\", \"Family Planning\", \"Contraception\"\n",
    "]\n",
    "\n",
    "driving_keywords = [\n",
    "    'capability to drive a car', 'driving', 'effects on ability to drive', 'driving and using machines', 'drive', \n",
    "    \"Driving\", \"Operate Machinery\",  \"Do Not Drive\", \n",
    "    \"not drive\", \"Driving and using machines\", \n"
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b3258",
   "metadata": {},
   "source": [
    "### Extract text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c2cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'ibuprofen_leaflet.pdf'  \n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "text = clean_text(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ffede",
   "metadata": {},
   "source": [
    "### Extract and summarize each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82850ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "composition_summary = extract_and_summarize(text, composition_keywords, contraindications_keywords)\n",
    "contraindications_summary = extract_and_summarize(text, contraindications_keywords, adverse_reactions_keywords)\n",
    "adverse_reactions_summary = extract_and_summarize(text, adverse_reactions_keywords, pregnancy_keywords)\n",
    "pregnancy_summary = extract_and_summarize(text, pregnancy_keywords, driving_keywords)\n",
    "driving_summary = extract_and_summarize(text, driving_keywords, ['end of document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0221016",
   "metadata": {},
   "source": [
    "### Creating DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3aee8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Composition</td>\n",
       "      <td>Ibuprofen 400 mg Tablets belongs to a grou p o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contraindications</td>\n",
       "      <td>Do not take if you:  have (or have had two or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adverse Reactions</td>\n",
       "      <td>Ibupr ofen is u seful for the relief of rheuma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancy</td>\n",
       "      <td>Pregna ncy and brea stfeeding Ibuprofen ta ble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capability to Drive</td>\n",
       "      <td>If aff ected by any of the following sy mptoms...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Section                                            Content\n",
       "0          Composition  Ibuprofen 400 mg Tablets belongs to a grou p o...\n",
       "1    Contraindications  Do not take if you:  have (or have had two or ...\n",
       "2    Adverse Reactions  Ibupr ofen is u seful for the relief of rheuma...\n",
       "3            Pregnancy  Pregna ncy and brea stfeeding Ibuprofen ta ble...\n",
       "4  Capability to Drive  If aff ected by any of the following sy mptoms..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Section\": [\"Composition\", \"Contraindications\", \"Adverse Reactions\", \"Pregnancy\", \"Capability to Drive\"],\n",
    "    \"Content\": [composition_summary, contraindications_summary, adverse_reactions_summary, pregnancy_summary, driving_summary]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c43853",
   "metadata": {},
   "source": [
    "### Loading Pre-trained model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abaf3bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca9ed0",
   "metadata": {},
   "source": [
    "### Creating context and ask question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a4ad0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: is it safe for me to drive while taking this medication?\n",
      "Answer: do not drive or o perat e machinery\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = clean_text(composition_summary + driving_summary + adverse_reactions_summary)\n",
    "question = \"is it safe for me to drive while taking this medication?\"\n",
    "answer = split_context(question, context)\n",
    "print(f\"Question: {question}\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758aedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
